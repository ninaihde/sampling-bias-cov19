{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EBI Metadata\n",
    "\n",
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata_ebi = pd.read_csv('../data/results_sequence_tsv.txt',\n",
    "                           sep='\\t',\n",
    "                           dtype={'collected_by': object,\n",
    "                                  'collection_date': object,\n",
    "                                  'culture_collection': object,\n",
    "                                  'identified_by': object,\n",
    "                                  'isolate': object,\n",
    "                                  'isolation_source': object,\n",
    "                                  'keywords': object,\n",
    "                                  'lab_host': object,\n",
    "                                  'location': object,\n",
    "                                  'sample_accession': object,\n",
    "                                  'strain': object,\n",
    "                                  'study_accession': object})\n",
    "\n",
    "metadata_ebi.info() # 51 cols, 2.5 mio entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show how many NaN values each col has\n",
    "metadata_ebi.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract names of cols containing only NaN values\n",
    "nan_cols = [i for i in metadata_ebi.columns if metadata_ebi[i].isnull().sum() == len(metadata_ebi)]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce data frame to relevant 29 cols (5 columns do still contain a lot of NaN values)\n",
    "metadata_ebi_relevant_cols = metadata_ebi.drop(nan_cols, axis=1)\n",
    "metadata_ebi_relevant_cols.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rename column and fill NaN values with empty strings\n",
    "metadata_ebi_relevant_cols.rename({'country': 'country_and_region'}, axis=1, inplace=True)\n",
    "metadata_ebi_relevant_cols['country_and_region'] = metadata_ebi_relevant_cols['country_and_region'].fillna('')\n",
    "\n",
    "# Save as CSV\n",
    "metadata_ebi_relevant_cols.to_csv('../data/metadata_EBI_relevant_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import json\n",
    "\n",
    "# Create fancy profile report\n",
    "# See https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/advanced_usage.html for advanced usage\n",
    "profile_ebi = pandas_profiling.ProfileReport(metadata_ebi_relevant_cols,\n",
    "                                             title='EBI Metadata Profiling',\n",
    "                                             minimal=True,\n",
    "                                             correlations={'pearson': {'calculate': True},\n",
    "                                                           'spearman': {'calculate': True},\n",
    "                                                           'kendall': {'calculate': True},\n",
    "                                                           'phi_k': {'calculate': True},\n",
    "                                                           'cramers': {'calculate': False}})\n",
    "\n",
    "# Add definitions\n",
    "with open('definitions_EBI_metadata.json') as f:\n",
    "    definitions_ebi_metadata = json.load(f)\n",
    "profile_ebi.config.variables.descriptions = definitions_ebi_metadata\n",
    "\n",
    "# Save as html\n",
    "profile_ebi.to_file(output_file='../data/profile_EBI_metadata.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Next Steps & Open Questions\n",
    "\n",
    "- are empty columns telling us something and which other columns can be deleted?\n",
    "-> meaning of cols & col values (like 'dataclass' categories)? 'location' = 'country'?\n",
    "- extract age and race from 'host' for data enrichment/ more insights/ correlations\n",
    "-> which other columns encode several information at once?\n",
    "- 'last_updated': count over time -> is there an unequal distribution over time? / temporal bias?\n",
    "- are there any empty or duplicate rows?\n",
    "- look at columns with a lot of missing values -> undercoverage/ negative set bias?\n",
    "- look at constant columns -> same 'tax_id', 'tax_division' or 'culture_collection' meaning overcoverage bias?\n",
    "- look at columns with high cardinality\n",
    "- how useful are correlation plots? -> do 'sequence_version' and 'base_count' correlate? 'identified_by' and 'base_count'? 'dataclass' and 'mol_type'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/metadata_EBI_relevant_cols.csv',\n",
    "                 dtype={'collected_by': object,\n",
    "                        'collection_date': object,\n",
    "                        'culture_collection': object,\n",
    "                        'identified_by': object,\n",
    "                        'isolate': object,\n",
    "                        'isolation_source': object,\n",
    "                        'keywords': object,\n",
    "                        'lab_host': object,\n",
    "                        'location': object,\n",
    "                        'sample_accession': object,\n",
    "                        'strain': object,\n",
    "                        'study_accession': object})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Which columns are not relevant for further analysis?\n",
    "cols_to_drop = ['scientific_name', # all 'SARS-CoV-2'\n",
    "                'sequence_md5', # MD5 checksum should have to further meaning as it is a hash value\n",
    "                'sequence_version', # nearly all version 1\n",
    "                'study_accession', # name of study accession should have no influence on biases or does it encode e.g. country?\n",
    "                'location', # same as country?\n",
    "                'environmental_sample' #?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup keyword column\n",
    "df['keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['keywords'].replace(['purposeofsampling:baselinesurveillance', 'puposeofsampling:baselinesurveillance', 'purpose_of_sequencing:baselinesurveillance', 'purposeofsampling=baselinesurveillance'], 'purpose_of_sampling:baseline_surveillance', inplace=True)\n",
    "df['keywords'].replace(['purposeofsampling:targetedefforts', 'purposeofsampling=targetedefforts'], 'purpose_of_sampling:targeted_efforts', inplace=True)\n",
    "df['keywords'].replace('purposeofsampling:targeted_sequencing', 'purpose_of_sampling:targeted_sequencing', inplace=True)\n",
    "\n",
    "df['keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add gender column\n",
    "df['host'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gender(host_value):\n",
    "    if any([substring in host_value.lower() for substring in ['female', 'femle', 'gender: f']]):\n",
    "        return 'female'\n",
    "    if any([substring in host_value.lower() for substring in ['male', 'gender: m']]):\n",
    "        return 'male'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['gender'] = df.apply(lambda row: get_gender(str(row['host'])), axis=1)\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Verify if all gender descriptions are catched\n",
    "df_unknown_gender = df[df['gender'] == 'unknown']\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df_unknown_gender['host'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add age column\n",
    "def get_age(host_value):\n",
    "    if 'age' in host_value.lower():\n",
    "        if host_value[host_value.lower().find('age') + 3] == ' ':\n",
    "            return host_value[(host_value.lower().find('age') + 4) : (host_value.lower().find('age') + 6)]\n",
    "        if host_value[host_value.lower().find('age') + 3] == ':':\n",
    "                if host_value[host_value.lower().find('age') + 4] == ' ':\n",
    "                    return host_value[(host_value.lower().find('age') + 5) : (host_value.lower().find('age') + 7)]\n",
    "                else:\n",
    "                    return host_value[(host_value.lower().find('age') + 4) : (host_value.lower().find('age') + 6)]\n",
    "        else:\n",
    "            return host_value[(host_value.lower().find('age') + 3) : (host_value.lower().find('age') + 5)]\n",
    "    if 'year old' in host_value.lower():\n",
    "        return host_value[(host_value.lower().find('year old') - 3) : (host_value.lower().find('year old') - 1)]\n",
    "\n",
    "df['age'] = df.apply(lambda row: get_age(str(row['host'])), axis=1)\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Check how host is set if age in not numeric\n",
    "df['age'] = df['age'].astype(str)\n",
    "df[df['age'].apply(lambda x: not x.isnumeric())][['age', 'host']]\n",
    "\n",
    "# TODO: Invest ages < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add race column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Investigation of National Bias (Undercoverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Extract country\n",
    "df['country_and_region'] = df['country_and_region'].astype(str)\n",
    "df['country'] = [country_and_region.split(':')[0] for country_and_region in df['country_and_region']]\n",
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/metadata_EBI_cleaned_and_enriched.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separate dataframe into countries appearing often and rarely\n",
    "threshold = 1000\n",
    "\n",
    "rare_countries = df[df['country'].map(df['country'].value_counts()) < threshold]\n",
    "rare_countries = rare_countries[rare_countries['country'] != '']\n",
    "rare_countries['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "popular_countries = df[df['country'].map(df['country'].value_counts()) >= threshold]\n",
    "popular_countries['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot distribution of countries appearing more than 1,000 times\n",
    "for hue in ['dataclass', 'mol_type', 'keywords', 'gender']:\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    sns.countplot(data=popular_countries,\n",
    "                  x='country',\n",
    "                  hue=hue,\n",
    "                  order=popular_countries['country'].value_counts().index)\n",
    "\n",
    "    fig.suptitle('Distribution of Countries with >= 1,000 Samples', fontsize=20)\n",
    "    plt.xlabel('Country', fontsize=16)\n",
    "    plt.ylabel('Count', fontsize=16)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    plt.legend(loc='upper right', title=f'{hue.capitalize()}:')\n",
    "\n",
    "    plt.savefig(f'../plots/popular_countries_count_by_{hue}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot distribution of countries appearing less than 1,000 times\n",
    "for hue in ['dataclass', 'mol_type', 'keywords', 'gender']:\n",
    "    fig, ax = plt.subplots(figsize=(36, 18))\n",
    "    sns.countplot(data=rare_countries,\n",
    "                  x='country',\n",
    "                  hue=hue,\n",
    "                  order=rare_countries['country'].value_counts().index)\n",
    "\n",
    "    fig.suptitle('Distribution of Countries with < 1,000 Samples', fontsize=20)\n",
    "    plt.xlabel('Country', fontsize=16)\n",
    "    plt.ylabel('Count', fontsize=16)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "    plt.legend(loc='upper right', title=f'{hue.capitalize()}:')\n",
    "\n",
    "    plt.savefig(f'../plots/rare_countries_count_by_{hue}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}