{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EBI Metadata\n",
    "\n",
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata_ebi = pd.read_csv('../data/results_sequence_tsv.txt',\n",
    "                           sep='\\t',\n",
    "                           dtype={'collected_by': object,\n",
    "                                  'collection_date': object,\n",
    "                                  'culture_collection': object,\n",
    "                                  'identified_by': object,\n",
    "                                  'isolate': object,\n",
    "                                  'isolation_source': object,\n",
    "                                  'keywords': object,\n",
    "                                  'lab_host': object,\n",
    "                                  'location': object,\n",
    "                                  'sample_accession': object,\n",
    "                                  'strain': object,\n",
    "                                  'study_accession': object})\n",
    "\n",
    "metadata_ebi.info() # 51 cols, 2.5 mio entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show how many NaN values each col has\n",
    "metadata_ebi.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract names of cols containing only NaN values\n",
    "nan_cols = [i for i in metadata_ebi.columns if metadata_ebi[i].isnull().sum() == len(metadata_ebi)]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce data frame to relevant 29 cols (5 columns do still contain a lot of NaN values)\n",
    "metadata_ebi_relevant_cols = metadata_ebi.drop(nan_cols, axis=1)\n",
    "metadata_ebi_relevant_cols.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rename column and fill NaN values with empty strings\n",
    "metadata_ebi_relevant_cols.rename({'country': 'country_and_region'}, axis=1, inplace=True)\n",
    "metadata_ebi_relevant_cols['country_and_region'] = metadata_ebi_relevant_cols['country_and_region'].fillna('')\n",
    "\n",
    "# Save as CSV\n",
    "metadata_ebi_relevant_cols.to_csv('../data/metadata_EBI_relevant_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import json\n",
    "\n",
    "# Create fancy profile report\n",
    "# See https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/advanced_usage.html for advanced usage\n",
    "profile_ebi = pandas_profiling.ProfileReport(metadata_ebi_relevant_cols,\n",
    "                                             title='EBI Metadata Profiling',\n",
    "                                             minimal=True,\n",
    "                                             correlations={'pearson': {'calculate': True},\n",
    "                                                           'spearman': {'calculate': True},\n",
    "                                                           'kendall': {'calculate': True},\n",
    "                                                           'phi_k': {'calculate': True},\n",
    "                                                           'cramers': {'calculate': False}})\n",
    "\n",
    "# Add definitions\n",
    "with open('definitions_EBI_metadata.json') as f:\n",
    "    definitions_ebi_metadata = json.load(f)\n",
    "profile_ebi.config.variables.descriptions = definitions_ebi_metadata\n",
    "\n",
    "# Save as html\n",
    "profile_ebi.to_file(output_file='../data/profile_EBI_metadata.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Next Steps & Open Questions\n",
    "\n",
    "- are empty columns telling us something and which other columns can be deleted?\n",
    "-> meaning of cols & col values (like 'dataclass' categories)? 'location' = 'country'?\n",
    "- extract age and race from 'host' for data enrichment/ more insights/ correlations\n",
    "-> which other columns encode several information at once?\n",
    "- 'last_updated': count over time -> is there an unequal distribution over time? / temporal bias?\n",
    "- are there any empty or duplicate rows?\n",
    "- look at columns with a lot of missing values -> undercoverage/ negative set bias?\n",
    "- look at constant columns -> same 'tax_id', 'tax_division' or 'culture_collection' meaning overcoverage bias?\n",
    "- look at columns with high cardinality\n",
    "- how useful are correlation plots? -> do 'sequence_version' and 'base_count' correlate? 'identified_by' and 'base_count'? 'dataclass' and 'mol_type'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/metadata_EBI_relevant_cols.csv',\n",
    "                 dtype={'collected_by': object,\n",
    "                        'collection_date': object,\n",
    "                        'culture_collection': object,\n",
    "                        'identified_by': object,\n",
    "                        'isolate': object,\n",
    "                        'isolation_source': object,\n",
    "                        'keywords': object,\n",
    "                        'lab_host': object,\n",
    "                        'location': object,\n",
    "                        'sample_accession': object,\n",
    "                        'strain': object,\n",
    "                        'study_accession': object})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Which columns are not relevant for further analysis?\n",
    "cols_to_drop = ['scientific_name', # all 'SARS-CoV-2'\n",
    "                'sequence_md5', # MD5 checksum should have to further meaning as it is a hash value\n",
    "                'sequence_version', # nearly all version 1\n",
    "                'study_accession', # name of study accession should have no influence on biases or does it encode e.g. country?\n",
    "                'location', # same as country?\n",
    "                'environmental_sample' #?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup keyword column\n",
    "df['keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['keywords'].replace(['purposeofsampling:baselinesurveillance', 'puposeofsampling:baselinesurveillance', 'purpose_of_sequencing:baselinesurveillance', 'purposeofsampling=baselinesurveillance'], 'purpose_of_sampling:baseline_surveillance', inplace=True)\n",
    "df['keywords'].replace(['purposeofsampling:targetedefforts', 'purposeofsampling=targetedefforts', 'purpose_of_sampling:targeted_sequencing'], 'purpose_of_sampling:targeted_efforts', inplace=True)\n",
    "df['keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add gender column\n",
    "df['host'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gender(host_value):\n",
    "    if any([substring in host_value.lower() for substring in ['female', 'femle', 'gender: f']]):\n",
    "        return 'female'\n",
    "    if any([substring in host_value.lower() for substring in ['male', 'gender: m']]):\n",
    "        return 'male'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['gender'] = df.apply(lambda row: get_gender(str(row['host'])), axis=1)\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Verify if all gender descriptions are catched\n",
    "df_unknown_gender = df[df['gender'] == 'unknown']\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df_unknown_gender['host'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add age column\n",
    "def get_age(host_value):\n",
    "    if 'age' in host_value.lower():\n",
    "        if host_value[host_value.lower().find('age') + 3] == ' ':\n",
    "            return host_value[(host_value.lower().find('age') + 4) : (host_value.lower().find('age') + 6)]\n",
    "        if host_value[host_value.lower().find('age') + 3] == ':':\n",
    "                if host_value[host_value.lower().find('age') + 4] == ' ':\n",
    "                    return host_value[(host_value.lower().find('age') + 5) : (host_value.lower().find('age') + 7)]\n",
    "                else:\n",
    "                    return host_value[(host_value.lower().find('age') + 4) : (host_value.lower().find('age') + 6)]\n",
    "        else:\n",
    "            return host_value[(host_value.lower().find('age') + 3) : (host_value.lower().find('age') + 5)]\n",
    "    if 'year old' in host_value.lower():\n",
    "        return host_value[(host_value.lower().find('year old') - 3) : (host_value.lower().find('year old') - 1)]\n",
    "\n",
    "df['age'] = df.apply(lambda row: get_age(str(row['host'])), axis=1)\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Check how host is set if age in not numeric\n",
    "df['age'] = df['age'].astype(str)\n",
    "df[df['age'].apply(lambda x: not x.isnumeric())][['age', 'host']]\n",
    "\n",
    "# TODO: Invest ages < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add race column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Investigation of National Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract country\n",
    "df['country_and_region'] = df['country_and_region'].astype(str)\n",
    "df['country'] = [country_and_region.split(':')[0] for country_and_region in df['country_and_region']]\n",
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "df['country'] = df['country'].replace(np.nan, 'Unknown')\n",
    "\n",
    "# Load number of inhabitants per country (taken from Wikipedia)\n",
    "with open('country_inhabitants_map.json') as f:\n",
    "    country_inhabitants_map = json.load(f)\n",
    "\n",
    "# Add new col with number of inhabitants\n",
    "df['n_inhabitants'] = df['country'].map(country_inhabitants_map)\n",
    "df['n_inhabitants'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/metadata_EBI_cleaned_and_enriched.csv', index=False)\n",
    "\n",
    "# TODO: execute profiling again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separate dataframe into countries appearing often and rarely\n",
    "threshold = 1000\n",
    "\n",
    "rare_countries = df[df['country'].map(df['country'].value_counts()) < threshold]\n",
    "rare_countries['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "popular_countries = df[df['country'].map(df['country'].value_counts()) >= threshold]\n",
    "popular_countries['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Plot distribution of countries appearing more than 1,000 times\n",
    "for hue in ['dataclass', 'mol_type', 'keywords', 'gender']:\n",
    "    fig, ax = plt.subplots(figsize=(18, 16))\n",
    "    sns.countplot(data=popular_countries,\n",
    "                  x='country',\n",
    "                  hue=hue,\n",
    "                  order=popular_countries['country'].value_counts().index)\n",
    "\n",
    "    fig.suptitle('Distribution of Countries with >= 1,000 Samples', fontsize=22)\n",
    "    plt.xlabel('Country', fontsize=18)\n",
    "    plt.ylabel('Count Normalized by Number of Inhabitants', fontsize=18)\n",
    "    plt.xticks(fontsize=14, rotation=90)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(loc='upper right', title=f'{hue.capitalize()}:', fontsize=14)\n",
    "    plt.rcParams['legend.title_fontsize'] = 14\n",
    "\n",
    "    # Normalize height of bars with number of inhabitants\n",
    "    max_y = 0\n",
    "    n_countries = len(popular_countries['country'].unique())\n",
    "    hue_index = 0\n",
    "\n",
    "    for i, patch in enumerate(ax.patches):\n",
    "        if i % n_countries == 0 and i != 0:\n",
    "            hue_index += 1\n",
    "        country = ax.get_xticklabels()[i - (hue_index * n_countries)].get_text()\n",
    "\n",
    "        new_height = patch.get_height() / country_inhabitants_map[country]\n",
    "        max_y = max(max_y, new_height)\n",
    "        patch.set_height(new_height)\n",
    "\n",
    "    plt.gca().set_ylim([0, max_y + (max_y / 20)])\n",
    "\n",
    "    plt.savefig(f'../plots/general_country_counts/popular_countries_count_by_{hue}_normalized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot distribution of countries appearing less than 1,000 times\n",
    "for hue in ['dataclass', 'mol_type', 'keywords', 'gender']:\n",
    "    fig, ax = plt.subplots(figsize=(36, 18))\n",
    "    sns.countplot(data=rare_countries,\n",
    "                  x='country',\n",
    "                  hue=hue,\n",
    "                  order=rare_countries['country'].value_counts().index)\n",
    "\n",
    "    fig.suptitle('Distribution of Countries with < 1,000 Samples', fontsize=22)\n",
    "    plt.xlabel('Country', fontsize=18)\n",
    "    plt.ylabel('Count Normalized by Number of Inhabitants', fontsize=18)\n",
    "    plt.xticks(fontsize=14, rotation=90)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(loc='upper right', title=f'{hue.capitalize()}:', fontsize=14)\n",
    "    plt.rcParams['legend.title_fontsize'] = 14\n",
    "\n",
    "    # Normalize height of bars with number of inhabitants\n",
    "    max_y = 0\n",
    "    n_countries = len(rare_countries['country'].unique())\n",
    "    hue_index = 0\n",
    "\n",
    "    for i, patch in enumerate(ax.patches):\n",
    "        if i % n_countries == 0 and i != 0:\n",
    "            hue_index += 1\n",
    "        country = ax.get_xticklabels()[i - (hue_index * n_countries)].get_text()\n",
    "\n",
    "        if country == 'Unknown':\n",
    "            new_height = 0.0\n",
    "        else:\n",
    "            new_height = patch.get_height() / country_inhabitants_map[country]\n",
    "\n",
    "        max_y = max(max_y, new_height)\n",
    "        patch.set_height(new_height)\n",
    "    plt.gca().set_ylim([0, max_y + (max_y / 20)])\n",
    "\n",
    "    plt.savefig(f'../plots/general_country_counts/rare_countries_count_by_{hue}_normalized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependance on Missing Values to Countries/ Institutes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_missing_vals = df.columns[df.isnull().any()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot country distribution for each column with missing values\n",
    "for col in cols_missing_vals:\n",
    "    df_temp = df[df[col].isna()][[col, 'country']]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(42, 22))\n",
    "    sns.countplot(data=df_temp,\n",
    "                  x='country',\n",
    "                  palette=['blue'] * len(df_temp['country']),\n",
    "                  order=df_temp['country'].value_counts().index)\n",
    "\n",
    "    fig.suptitle(f'Distribution of Countries for Rows with Missing Values in \"{col}\"', fontsize=22)\n",
    "    plt.xlabel('Country', fontsize=18)\n",
    "    plt.ylabel('Count Normalized by Number of Inhabitants', fontsize=18)\n",
    "    plt.xticks(fontsize=14, rotation=90)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Normalize height of bars with number of inhabitants\n",
    "    for i, patch in enumerate(ax.patches):\n",
    "        country = ax.get_xticklabels()[i].get_text()\n",
    "        if country == 'Unknown':\n",
    "            new_height = 0.0\n",
    "        else:\n",
    "            new_height = patch.get_height() / country_inhabitants_map[country]\n",
    "\n",
    "        max_y = max(max_y, new_height)\n",
    "        patch.set_height(new_height)\n",
    "    plt.gca().set_ylim([0, max_y + (max_y / 20)])\n",
    "\n",
    "    plt.savefig(f'../plots/missing_vals/country_count_of_missing_vals_in_{col}_normalized.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['collected_by'].value_counts() # 385 unique entries -> cannot create above plots for this column (at least not out-of-the-box)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}